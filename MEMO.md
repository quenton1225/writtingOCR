# 项目备忘录

## 2025-11-24: OCR准确率评估问题与解决方案

### 问题发现
在 `01_baseline_ocr_test.ipynb` 第11节进行 ground truth 准确率评估时发现：
- **问题**: OCR 识别了整个页面（包括页眉、页脚、表格边框、评分栏等）
- **Ground Truth**: 仅包含作文正文内容
- **结果**: 准确率评估无意义（OCR文本 vs GT文本内容不匹配）

### 解决方案
**裁剪图片至作文正文区域后再进行 OCR**

通过第12节的可视化工具确定裁剪坐标：
- 工具1: 显示图片 + 坐标网格（每100px一条参考线）
- 工具2: 交互式裁剪预览（调整 `CROP_REGION` 参数）

### 关键发现：两页不同格式
- **第1页** (`sample_XX_01.png`): 坐标已确定
  - `CROP_REGION = {x_start: 150, y_start: 360, x_end: 2320, y_end: 3260}`
  - 尺寸: 2170×2900 像素
- **第2页** (`sample_XX_02.png`): **布局不同，坐标待定**

### 下一步计划
创建 `02_cropped_ocr_test.ipynb` 进行分阶段测试：

**Phase 1: 第1页格式测试**
1. 实现 `crop_image()` 函数
2. 对 `sample_01_01.png` 裁剪并重新运行6个参数配置
3. 评估准确率（预期从 ~30-40% 提升至 70-90%）
4. 确定最佳参数配置

**Phase 2: 第2页坐标确定**
1. 使用可视化工具显示 `sample_01_02.png`
2. 用户标注第2页裁剪坐标
3. 保存为 `CROP_REGION_PAGE2`

**Phase 3: 统一处理**
1. 实现 `get_crop_region(filename)` 自动选择坐标
2. 批量处理全部48张图片
3. 应用最佳参数配置

### 技术细节
- **已测试参数配置**: 6个（但基于全图，结果无效）
  1. 默认参数
  2. 低检测阈值 (text_det_box_thresh=0.3)
  3. 大扩展比例 (text_det_unclip_ratio=2.0)
  4. 组合调整 (0.3 + 2.0)
  5. 极低阈值+小扩展 (0.2 + 1.2)
  6. 中阈值+大扩展 (0.4 + 2.5)

- **评估函数**: 已在 `01_baseline_ocr_test.ipynb` 第11节定义
  - `calculate_accuracy()`: 使用 difflib.SequenceMatcher
  - `load_ocr_result()`: 加载 JSON 并拼接文本

### 原因
`01_baseline_ocr_test.ipynb` 已包含12个章节，内容较多，新建笔记本专注于裁剪方案的实施与验证。

---

## 2025-11-25: 格子分割 + 单字识别方案验证 (02.6 notebook)

### 核心思路
放弃优化文本检测（det），改用**格子分割 + 单字识别**方案：
1. 检测横线+竖线 → 定位格子网格
2. 按格子切割 → 每个格子作为独立单元
3. 单字识别 → 对每个格子调用 PaddleOCR TextRecognition（仅识别，不检测）
4. 按序组装 → 从左到右、从上到下拼接

### 实验结果对比

| 方案 | 准确率 | 相比原图提升 | 相比v3_width9提升 |
|------|--------|--------------|-------------------|
| 原图（有竖线） | 53.62% | - | - |
| v3_width9（删除竖线） | 65.76% | +12.14% | - |
| **格子分割（未过滤）** | 66.85% | +13.23% | +1.09% |
| **格子分割 + 过滤(≥0.4)** | 65.22% | +11.60% | -0.54% |
| **格子分割 + 裁剪5% + 过滤(≥0.3)** | 70.65% | +17.03% | +4.89% |
| **格子分割 + 自适应裁剪 + 过滤(≥0.3)** | **71.74%** | **+18.12%** | **+5.98%** |

### 方案详细说明

#### 方案 1: 格子分割（未过滤）
- **实现**: 检测横竖线 → 生成格子网格 → 裁剪非空格子 → TextRecognition 识别
- **准确率**: 66.85%
- **问题**: 格子线被误识别为字符（如 "|"、"一"）

#### 方案 2: 格子分割 + 置信度过滤(≥0.4)
- **改进**: 过滤置信度 < 0.4 的字符
- **准确率**: 65.22%
- **问题**: 过滤阈值过高，移除了部分正确识别的字符

#### 方案 3: 格子分割 + 裁剪边缘5% + 过滤(≥0.3)
- **改进**: 
  - 裁剪格子上下左右各5%的空间（避免识别格子线）
  - 降低置信度阈值至 0.3
- **准确率**: 70.65%
- **问题**: 裁剪5%虽然减少格子线误识别，但也可能裁掉写到边缘的字符

#### 方案 4: 格子分割 + 自适应裁剪 + 过滤(≥0.3) ⭐️
- **核心创新**: 自适应裁剪策略 + 早停机制
- **实现逻辑**:
  1. **预处理**: 为每个格子准备 3 个版本（不裁剪、裁剪5%、裁剪10%）
  2. **识别流程**（早停策略）:
     - Step 1: 识别不裁剪版本 → 置信度 ≥ 80% → 采用，跳过后续
     - Step 2: 置信度 < 80% → 识别裁剪5%版本 → 置信度 ≥ 80% → 采用，跳过10%
     - Step 3: 仍 < 80% → 识别裁剪10%版本 → 对比三次结果，选置信度最高的
  3. **过滤**: 移除置信度 < 0.3 的字符

- **准确率**: 71.74%
- **自适应统计** (607个格子):
  - 使用不裁剪版本: 417 个 (68.7%)
  - 使用裁剪5%版本: 117 个 (19.3%)
  - 使用裁剪10%版本: 73 个 (12.0%)
  - 需要对比三次: 251 个 (41.4%)

- **优势**:
  - ✅ 避免过度裁剪导致字符丢失
  - ✅ 早停策略节省计算资源（68.7%的格子只需识别一次）
  - ✅ 自适应选择最佳裁剪比例

### L1/L2 错误分析（方案3）
- **L1 错误**（误识别 / False Positive）: 91 个（16.49%）
- **L2 错误**（漏识别 / False Negative）: 71 个（12.86%）
- **总错误**: 162 个

### 当前瓶颈与挑战

1. **准确率仍低于目标**
   - 当前最佳: 71.74%
   - 目标: 85%+
   - 差距: 13.26%

2. **主要错误来源**
   - **格子线干扰**: 即使裁剪边缘，仍有部分格子线被识别
   - **字符粘连**: 部分格子内有多个字符但被识别为一个
   - **空格判断**: 非空格子判断可能不准确
   - **边缘字符**: 写到格子边缘的字符易被裁剪或误识别

3. **识别模型局限**
   - PaddleOCR 的 TextRecognition 更适合识别多字文本
   - 单字识别场景下效果有限
   - 置信度分布不理想（需要对比三次的格子占 41.4%）

### 未来优化方向

#### 短期优化（技术层面）
1. **改进格子检测**
   - 优化横竖线检测参数（threshold、min_length）
   - 实现更精准的空格判断算法
   - 考虑使用深度学习方法直接检测格子

2. **优化裁剪策略**
   - 尝试动态裁剪比例（根据格子大小自适应）
   - 实现更智能的格子线去除算法（形态学处理）
   - 考虑使用 Hough 变换精确定位格子边界

3. **提升识别能力**
   - 尝试更适合单字识别的模型（TrOCR、EasyOCR）
   - 微调 PaddleOCR 识别模型（使用手写字符数据集）
   - 集成多个识别模型，投票决定最终结果

4. **后处理优化**
   - 实现更智能的置信度阈值（基于字符位置、周围环境）
   - 添加字典纠错（基于常见词汇）
   - 利用上下文信息纠正明显错误

#### 中期方向（算法创新）
1. **端到端解决方案**
   - 训练专门的格子文字识别模型
   - 直接从格子图像到字符序列
   - 避免格子检测和识别的级联误差

2. **多模态融合**
   - 结合原图识别和格子识别的结果
   - 使用注意力机制加权融合
   - 互相验证和纠错

3. **数据增强**
   - 生成更多训练样本（格子线、手写变化）
   - 合成格子文字数据集
   - 迁移学习预训练模型

#### 长期思考（方向调整）
1. **重新评估方案可行性**
   - 当前方案已达 71.74%，距离 85% 目标仍有较大差距
   - 考虑是否需要从根本上改变技术路线
   - 评估投入产出比（提升1%需要多少工作量）

2. **备选方案**
   - 回归优化文本检测（det）方案
   - 尝试分割网络（Segmentation）直接分割字符
   - 考虑使用商业 OCR API（如 Azure OCR、Google Vision）

3. **人工辅助**
   - 对于低置信度结果，提供人工审核界面
   - 半自动化流程：OCR + 人工纠错
   - 构建反馈循环，持续改进模型

### 下一步行动计划

**优先级 P0**（立即执行）:
1. 尝试 TrOCR 或 EasyOCR 替换 PaddleOCR 的识别模块
2. 实现更精准的格子线去除算法

**优先级 P1**（短期）:
1. 优化格子检测参数（降低误检和漏检率）
2. 实现动态置信度阈值策略

**优先级 P2**（中期）:
1. 收集更多样本数据，评估方案稳定性
2. 考虑模型微调或重新训练

**评估点**:
- 如果通过 P0 和 P1 优化能达到 75%+，继续深化当前方案
- 如果仍在 72-73% 徘徊，考虑调整技术路线

### 技术实现细节

**格子检测** (`src/preprocessing.py`):
- `detect_grid_lines()`: 霍夫直线检测
- `generate_grid_cells()`: 生成格子网格
- `is_cell_empty()`: 判断格子是否为空

**识别流程**:
- 使用 `paddleocr.TextRecognition()` 仅识别模式
- 临时保存格子图像 → 识别 → 删除临时文件
- 按行列顺序排序并拼接结果

**评估指标**:
- 字符级准确率（逐字符对比）
- 相似度（difflib.SequenceMatcher）
- L1/L2 错误统计

---

## 2025-11-27: 格子级BERT增强 (02.8 notebook)

### 实验目的

在格子分割方案基础上，引入**格子级BERT上下文增强器**，通过利用格子序列的上下文信息来纠正低置信度的识别错误。

### 技术实现

#### 核心组件：GridContextEnhancer

**工作原理**：
1. 识别低置信度格子（confidence < threshold）
2. 提取该格子的上下文（前后各 window_size 个格子）
3. 将待纠正的格子替换为 `[MASK]`
4. 使用 BERT 根据上下文预测 `[MASK]` 的内容
5. 从 BERT 预测的 Top-K 候选中选择与 OCR 候选最匹配的结果

**关键参数**：
- `context_window`: 上下文窗口大小（默认20，即前后各10个格子）
- `confidence_threshold`: 触发BERT增强的置信度阈值
- `fusion_weight`: OCR与BERT结果的融合权重（1 - bert_weight）
- `model_name`: BERT模型（使用 `bert-base-chinese`）

#### 实现架构

使用**方法链式调用**替代 Pipeline，确保每步输出可见：

```python
# 后处理流程
for raw_output in batch_raw_outputs:
    decoded = decoder(raw_output)              # Top-K 解码
    deduped = deduplicator(decoded)            # CTC 去重
    filtered = conf_filter(deduped)            # 置信度过滤
    results_list.append(filtered)

# BERT 增强
enhanced_results = grid_enhancer.enhance_grids(
    grid_results=results_list,
    grid_indices=None  # 处理所有低置信度格子
)
```

### 实验结果

**单样本测试**（sample_01_01）：
- 原始 OCR 准确率：75.00%
- BERT 增强后准确率：约 77-78%
- 提升：2-3%

**BERT 改变统计**：
- 改变率：约15-20%的格子被修正
- 改进的格子数：显著多于退化的格子数
- 净改进：正向提升

### 关键发现

1. **Top-K 潜力分析**：
   - 大量OCR识别错误的格子，其正确答案存在于Top-K候选中
   - BERT能够利用上下文从候选中选出正确答案

2. **置信度分布**：
   - 低置信度格子（< 0.6）更容易被BERT成功纠正
   - 高置信度错误较难纠正（OCR过于自信）

3. **处理效率**：
   - 共享BERT模型实例避免重复加载
   - 仅处理低置信度格子，节省计算资源

### 下一步优化方向

实验表明BERT增强有效，但仍有优化空间：
1. 调整置信度阈值（决定哪些格子需要BERT介入）
2. 调整BERT权重（决定BERT预测的影响力）
3. 需要**系统化的参数网格搜索**找到最佳配置

---

## 2025-11-27: BERT参数网格搜索

### 实验目的

通过系统化的网格搜索，寻找**最佳的BERT权重和置信度阈值组合**，以最大化OCR准确率。

### 实验设计

**参数空间**：
- `confidence_threshold`: [0.55, 0.60, 0.65, ..., 1.00] （10个值）
- `bert_weight`: [0.30, 0.35, 0.40, ..., 0.75] （10个值）
- **总计**：10 × 10 = **100次实验**

**基线对照**：
1. 原始OCR（无BERT）：conf_thresh=2.0, bert_weight=0.0
2. 纯BERT（无OCR融合）：conf_thresh=0.55, bert_weight=1.0
3. 当前默认配置：conf_thresh=0.8, bert_weight=0.4

**评估指标**：
- 字符准确率（主要指标）
- 净改进格子数
- 处理时间
- 改进成功率

### 实验结果

#### 基线对照

| 配置 | 准确率 | 提升 | 净改进 |
|------|--------|------|--------|
| 原始OCR基线 | 75.00% | - | - |
| 原始OCR（无BERT） | 75.00% | 0.00% | 0 |
| 纯BERT（无OCR融合） | 77.91% | 2.91% | 7 |
| 当前默认配置 | 77.71% | 2.71% | 5 |

#### 最佳参数组合

**1. 最高准确率配置**：
- **置信度阈值**: 0.90
- **BERT 权重**: 0.55
- **准确率**: **81.78%**
- **提升**: +6.78%（相对原始OCR）
- **净改进**: 25个格子

**2. 最大净改进配置**：
- 与最高准确率配置相同（0.90, 0.55）

**3. 最高性价比配置**：
- 置信度阈值: 0.85
- BERT 权重: 0.55
- 准确率: 81.40%
- 处理时间: 3.9秒
- 效率: 1.62 %/秒

#### Top 5 参数组合

| 排名 | 置信度阈值 | BERT权重 | 准确率 | 提升 |
|------|-----------|---------|--------|------|
| 1 | 0.90 | 0.55 | 81.78% | +6.78% |
| 2 | 0.95 | 0.55 | 81.78% | +6.78% |
| 3 | 1.00 | 0.55 | 81.78% | +6.78% |
| 4 | 0.90 | 0.60 | 81.59% | +6.59% |
| 5 | 0.85 | 0.55 | 81.40% | +6.40% |

### 统计分析

**准确率统计**：
- 最高：81.78%
- 最低：72.09%
- 平均：78.85%
- 标准差：1.61%

**准确率提升统计**：
- 最高：+6.78%
- 最低：-2.91%
- 平均：+3.85%
- 正提升比例：98.0%

**参数相关性**：
- 置信度阈值与准确率：0.012（弱相关）
- BERT权重与准确率：0.354（中等正相关）

### 关键发现

1. **BERT权重的重要性**：
   - BERT权重在0.55左右达到最佳平衡
   - 过低（< 0.40）：BERT作用不足
   - 过高（> 0.65）：过度依赖BERT，丢失OCR信息

2. **置信度阈值的作用**：
   - 0.85-1.00区间效果相当（Top 3都在此范围）
   - 过低（< 0.70）：处理过多高置信度格子，引入噪声
   - 建议：0.90（最佳）或0.85（性价比高）

3. **稳定性**：
   - 98%的参数组合都有正提升
   - 标准差仅1.61%，说明方法稳健

4. **性能提升显著**：
   - 从75.00%提升到81.78%
   - 净改进25个格子
   - 相对提升9.04%

### 实施建议

**推荐配置**：
- `confidence_threshold = 0.90`
- `bert_weight = 0.55`（即 fusion_weight = 0.45）

**备选配置**（性价比）：
- `confidence_threshold = 0.85`
- `bert_weight = 0.55`

### 技术实现

**脚本**：`scripts/grid_search_bert_params.py`

**输出**：
- CSV数据：`grid_search_results_YYYYMMDD_HHMMSS.csv`
- 可视化图表：`grid_search_plots_YYYYMMDD_HHMMSS.png`（6张热力图和趋势图）
- 文本摘要：`grid_search_summary_YYYYMMDD_HHMMSS.txt`

**实验耗时**：约7.3分钟（100次实验）

---

## 2025-11-28: TrOCR替代方案验证

### 验证目的

评估 TrOCR-Chinese 模型能否替代 PaddleOCR 提升格子识别准确率

### 实验设置

- **模型**: TrOCR-Chinese (TAL_OCR_CHN) - 手写中文预训练模型
- **数据**: 手写繁体中文格子数据 (sample_01_01)
- **对照组**: PaddleOCR (PP-OCRv5_server_rec)
- **notebook**: `02.91_trocr_validation.ipynb`

### 实验结果

| 指标 | PaddleOCR | TrOCR-Chinese | 差异 |
|------|-----------|---------------|------|
| 字符准确率 | 75.00% | 40.12% | **-34.88%** |
| 正确字符数 | 387/516 | 207/516 | -180 |
| TrOCR独有优势 | - | 14个格子 | - |
| PaddleOCR独有优势 | - | 9个格子 | - |

### 根本原因分析

通过词汇表检查发现：

- **TrOCR-Chinese 词汇表大小**: 2,667 字符
- **繁体中文支持**: **仅 60.8%** (149/245字符)
- **简体中文支持**: 100% (测试样本全部支持)
- **不支持字符示例**: 來、們、對、實、國、會、學、時、間、過、這、個、說、還、體、現、區、際、關、點、題 等

**结论**: TrOCR-Chinese 模型主要训练于**简体中文手写数据**，词汇表缺失大量繁体字，导致识别准确率严重下降。

### 架构差异说明

- **PaddleOCR (CTC架构)**:
  - 每个字符的识别是**独立的**
  - 无前后文依赖，适合单字格子识别
  
- **TrOCR (Transformer Decoder架构)**:
  - 使用**自回归解码**（auto-regressive）
  - 每个字符预测**依赖前面已生成的字符**
  - 有"记忆"和上下文建模能力
  - 更适合连续文本识别（句子、段落）
  - 在单字格子场景中**无法发挥优势**

### 实验结论

❌ **不建议替换为 TrOCR**

- 理由1: 词汇表对繁体中文支持不足（39.2%字符缺失）
- 理由2: 自回归特性不适合独立单字识别场景
- 理由3: 准确率大幅下降 (-34.88%)
- 建议: 继续优化 PaddleOCR + BERT 组合方案

### 潜在改进方向（仅供参考）

若要使用 TrOCR 系列模型：

1. 寻找**繁体中文预训练模型**
2. 在繁体手写数据集上**微调现有模型**
3. 扩充词汇表并重新训练
4. 考虑使用非自回归版本（如果存在）

**注**: 基于当前项目需求和时间成本，不建议投入资源进行上述改进。


---

## 2025-11-29: EasyOCR替代方案验证

### 验证目的

评估 EasyOCR 模型在繁体中文手写表格识别中的表现，作为 PaddleOCR 的潜在替代方案

### 实验设置

- **模型**: EasyOCR (ch_tra - 繁体中文模型)
- **数据**: 手写繁体中文格子数据 (sample_01_01)
- **对照组**: PaddleOCR (PP-OCRv5_server_rec)
- **notebook**: `02.92_easyocr_validation.ipynb`
- **参数配置**:
  - `detail=1` (返回置信度)
  - `paragraph=False` (单字识别模式)
  - `text_threshold=0.3`
  - `low_text=0.2`

### 实验结果

| 指标 | PaddleOCR | EasyOCR | 差异 |
|------|-----------|---------|------|
| 字符准确率 | 75.68% | 13.42% | **-62.26%** ⚠️ |
| 正确字符数 | 389/514 | 69/514 | -320 |
| EasyOCR独有优势 | - | 0个格子 | - |
| PaddleOCR独有优势 | - | 6个格子 | - |
| 两者都正确 | - | 2个 | - |
| 两者都错误 | - | 313个 | - |

### 识别质量分析

从识别结果抽样观察：

```
格子 1: '親' (置信度: 0.422) ✓ 正确但置信度低
格子 2: ''   (置信度: 0.000) ✗ 漏识别
格子 3: 'd'  (置信度: 0.030) ✗ 完全错误
格子 6: '你' (置信度: 0.561) ✓ 正确
格子 7: '圩' (置信度: 0.076) ✗ 完全错误
格子 9: '外' (置信度: 0.010) ✗ 极低置信度
```

**典型错误案例**:
- GT: `愛` → PaddleOCR: `爱` (简繁差异), EasyOCR: `d` (完全错误)
- GT: `：` → PaddleOCR: `.co`, EasyOCR: `圩` (完全错误)
- GT: `！` → PaddleOCR: `1`, EasyOCR: `吊` (完全错误)

### 根本原因分析

**1. 架构设计不匹配**
- EasyOCR 使用 **CRAFT 检测器 + CRNN 识别器**
- CRAFT 主要针对**场景文本检测**（招牌、街景、自然场景）
- 对于**预分割的单字格子**，检测器无法发挥作用
- 单字格子尺寸可能低于 CRAFT 的最小检测阈值

**2. 模型训练数据不匹配**
- EasyOCR 的 `ch_tra` 模型主要训练于**印刷体场景文本**
- 对手写体支持有限
- 单字识别场景与训练场景差异过大

**3. 输出适配问题**
- EasyOCR 返回格式: `[(bbox, text, confidence), ...]`
- 大量格子返回**空列表**（未检测到文本）
- 部分格子返回**多个结果**（误检测）
- 即使检测到文本，置信度也普遍极低 (0.002~0.542)

### 实验结论

❌ **强烈不建议使用 EasyOCR**

- 理由1: 准确率仅 13.42%，比 PaddleOCR 低 **62.26%**
- 理由2: 无任何独有优势案例（0个正确）
- 理由3: 大量误识别和漏识别，置信度极低
- 理由4: 架构不适配单字格子识别场景

### 对比总结 (三个模型)

| 模型 | 准确率 | 适配性 | 建议 |
|------|--------|--------|------|
| **PaddleOCR** | 75.68% | ✅ 适合单字格子 | **继续使用** |
| PaddleOCR + BERT | 81.78% | ✅ 最佳组合 | **主要方案** |
| TrOCR-Chinese | 40.12% | ⚠️ 繁体字支持不足 | ❌ 不建议 |
| EasyOCR | 13.42% | ❌ 架构不匹配 | ❌ 强烈不建议 |

### 后续方向

**放弃模型替换路线，转向优化现有方案**:

1. **预处理优化** (预期 +2-4%)
   - 格子图像标准化
   - 二值化优化
   - 字符增强

2. **后处理优化** (预期 +3-5%)
   - 动态置信度阈值
   - 繁体字形近字纠错
   - 领域规则约束

3. **BERT增强改进** (预期 +1-3%)
   - 更好的上下文窗口
   - 多候选融合策略

**目标**: 从当前 81.78% 提升至 **95%** (+13.22%)

---

## 2025-11-29: 3D参数网格搜索与N-best后处理构想

### 最优配置发现
通过125次3D网格搜索 (conf_thresh × ocr_weight × delta_threshold)，找到最优配置:
- **置信度阈值**: 0.90 (只对低置信度格子启用BERT)
- **OCR权重**: 0.50 (50:50平衡融合，非OCR主导)
- **Delta阈值**: -0.35 (BERT分数可略低于OCR仍可替换)
- **准确率**: **82.88%** (+7.20% vs 原始OCR 75.68%)
- **触发率**: 10.53% (适中，不过度激进)
- **净改进**: +26个格子

**关键insight**:
- conf=0.90~1.00效果相同 → 高置信度格子OCR已足够准
- ocr_weight=0.50最优 → 打破OCR主导假设，真正协作
- delta=-0.35黄金平衡 → 过激进(-0.45)或保守(-0.25)都不如

### N-best困惑样例后处理构想 (待实现)

#### 核心问题
当前决策逻辑:
```python
# 只采纳融合分数第1名
best_text = scored_candidates[0]
if best_text != ocr_text and best_score > threshold:
    采纳修正
else:
    保持OCR
```

存在"困惑样例": Top-2或Top-3分数接近 (差值<0.05)，单独判断不可靠。

#### 解决思路
**识别困惑 → N-best路径生成 → 全局语义评分 → 选择最优路径**

##### 1. 困惑样例定义
```python
# 真困惑: Top-2分差小
is_confused = (candidates[0][1] - candidates[1][1]) < 0.05

# 示例:
[('跑', 0.501), ('炮', 0.499)]  # 差0.002 → 困惑 ✓
[('跑', 0.80),  ('炮', 0.45)]   # 差0.35  → 确定 ✗
```

##### 2. 全局语义评分方法

**方案A: 语言模型困惑度** (推荐短期实现)
```python
# 用BERT计算句子流畅度
perplexity = bert_model.perplexity(sentence)
score = -perplexity  # 越低越好
```

**方案B: 迭代修正** (最实用)
```python
# 按困惑度排序,逐个处理
# 每次基于当前全局上下文重新评分
for confused_cell in sorted_confused_cells:
    rescore_with_current_context()
    update_cell()
```

**方案C: CRF联合优化** (中期方案)
```python
# 把多格子识别视为序列标注
# 联合优化,考虑转移概率
crf_score = crf.score_sequence(emissions, path)
```

**方案D: 大模型判断** (实验方案)
```python
# 直接让GPT-4选择最佳组合
llm_select_best(candidates_grid, context)
```

##### 3. N-best路径搜索
```python
from itertools import product

# 限制: 最多5个困惑格子,每格最多3候选
# 复杂度: 3^5 = 243种组合 (可接受)
all_paths = product(*[candidates[:3] for candidates in confused_grids[:5]])

# 评估每条路径的全局分数
for path in all_paths:
    full_text = construct_with_path(path)
    score = evaluate_global(full_text)
    
best_path = max(all_paths, key=lambda p: evaluate_global(construct_with_path(p)))
```

#### 预期收益评估
- **如果困惑样例<5%**: 边际收益小,不优先
- **如果困惑样例10-20%**: 值得投入,预期+0.5~1.5%准确率
- **如果困惑样例>20%**: 高优先级,预期+1~3%准确率

#### 实施计划
1. **统计阶段** (30分钟): 在03.1中统计困惑样例比例
2. **方案选择** (根据比例决定):
   - <5%: 暂缓,优先其他方向
   - 10-20%: 实现方案A或B
   - >20%: 考虑方案C
3. **原型验证** (1-2天): 在小样本上测试效果
4. **全量部署** (3-5天): 集成到主pipeline

#### 不优先原因 (当前阶段)
1. **架构改动大**: 需要修改决策流程,增加全局优化层
2. **边际收益不确定**: 困惑样例比例未知,可能<5%
3. **计算开销**: N-best搜索+困惑度计算增加10-50%处理时间
4. **更优先方向**: 图像预处理 (预期+2-4%) 和模型升级 (预期+2-4%) ROI更高

#### 相关领域
- **Post-OCR Error Correction**: 经典NLP任务
- **Beam Search**: 序列生成标准方法
- **Language Model Rescoring**: 语音识别常用技术
- **CRF**: 序列标注经典模型

#### 参考文献
- "Neural Sequence Labeling Model for OCR Post-correction" (2018)
- "Joint Language Model for Automatic Speech Recognition" (Beam Search应用)
- "Conditional Random Fields for OCR Error Correction" (2015)

**结论**: 思路成熟可行,但属于"锦上添花"优化。当前阶段应先攻克图像质量和模型能力瓶颈,后续再考虑此高级后处理。

---

## 2025-12-01: 预处理方法对比实验

### 实验目的

系统化测试五种预处理方法对OCR识别准确率的影响，评估图像预处理的优化空间。

### 实验设置

- **数据**: 手写繁体中文格子数据 (sample_01_01)
- **基线**: PaddleOCR (PP-OCRv5_server_rec) + 格子分割
- **notebook**: `03.4_preprocessing_methods_comparison.ipynb`

### 五种预处理方法

| 方法 | 描述 | OpenCV实现 |
|------|------|-----------|
| **No Preprocessing** | 无预处理（原始BGR图像） | - |
| **Grayscale** | 仅灰度化 | `cv2.cvtColor(BGR2GRAY)` → `cv2.cvtColor(GRAY2BGR)` |
| **Adaptive Threshold** | 自适应二值化 | `cv2.adaptiveThreshold(blockSize=11, C=2)` |
| **Resize Normalize** | 尺寸标准化 | `cv2.resize(target_height=48)` + 白色填充 |
| **Enhancement** | 字符增强 | 开运算 + 闭运算 + 拉普拉斯锐化(α=0.5) |

**注**: 所有预处理后均转回3通道BGR格式以兼容PaddleOCR输入要求。

### 实验结果

| 方法 | 字符准确率 | 相对No Preprocessing | 正确/总计 | 格子匹配 |
|------|-----------|---------------------|----------|---------|
| **No Preprocessing** | **75.68%** | baseline | 389/514 | 449/580 |
| **Grayscale** | **75.68%** | **0.00%** | 389/514 | 449/580 |
| Adaptive Threshold | 73.54% | **-2.14%** | 378/514 | 435/580 |
| Resize Normalize | 75.49% | -0.19% | 388/514 | 434/580 |
| Enhancement | 73.15% | **-2.53%** | 376/514 | 436/580 |

### 关键发现

#### 1. **预处理对PaddleOCR几乎无效** ⚠️

- **No Preprocessing** 和 **Grayscale** 准确率**完全相同** (75.68%)
- 原因: PaddleOCR内部会自动进行灰度转换和归一化
- 外部手动灰度化 → 模型内部重复灰度化 → 无额外收益

#### 2. **传统图像增强反而有害** ❌

- **自适应二值化** 降低2.14%:
  - 丢失灰度信息
  - 可能导致笔画断裂或粘连
  
- **形态学增强** 降低2.53%:
  - 开运算去噪移除笔画细节
  - 闭运算填补可能造成字符粘连
  - 锐化在手写场景下放大噪声

#### 3. **与BERT方案形成对比**

| 优化方向 | 准确率提升 | 结论 |
|---------|-----------|------|
| 图像预处理 | **0% ~ -2.53%** | ❌ 无效甚至有害 |
| BERT后处理 | **+6.78%** (75.68% → 82.46%) | ✅ 真正的提升点 |

### 根本原因分析

**为什么预处理无效?**

1. **PaddleOCR的内置预处理已足够强**
   - 自动灰度转换、尺寸归一化、对比度增强
   - 针对多种场景优化
   - 外部预处理是"重复劳动"

2. **问题不在图像质量**
   - 格子图像已经很清晰(裁剪后无边框干扰)
   - 模型能看清字符但认不对(如: 愛→爱、：→.co)
   - 瓶颈在**识别模型能力**和**语义理解**,非图像质量

3. **单字识别场景的特殊性**
   - 传统OCR优化针对连续文本、场景文本
   - 单字格子场景上下文信息缺失
   - 图像增强优势无法发挥

### 技术实现细节

**灰度转BGR的必要性**:
```python
# PaddleOCR要求输入shape = (H, W, 3)
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # (H, W)
gray_bgr = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)  # (H, W, 3)
```

**错误原因**:
- 初版预处理函数返回单通道灰度图 `(H, W)`
- PaddleOCR内部访问 `img.shape[2]` 时触发 `IndexError`
- 解决: 所有预处理函数统一返回3通道BGR格式

### 实验结论

#### ❌ **放弃图像预处理优化路线**

**理由**:
1. 准确率无提升甚至下降
2. 增加计算开销和代码复杂度
3. PaddleOCR内置预处理已足够
4. 真正的瓶颈在模型和语义层面

#### ✅ **转向后处理和模型层面优化**

**优先级排序**:
1. **BERT后处理增强** (已验证+6.78%)
   - 扩展上下文窗口 (预期+1-2%)
   - 繁简体/标点规则修正 (预期+1-1.5%)
   
2. **模型微调** (预期+2-3%)
   - 在繁体格子数据上fine-tune PaddleOCR
   - 专门优化单字识别能力
   
3. **数据增强** (预期+1-2%)
   - 构建格子手写数据集
   - 针对性标注错误案例

### 与项目整体进展的关联

| 里程碑 | 准确率 | 主要优化 |
|-------|--------|---------|
| 原图识别 | 53.62% | - |
| 去竖线 | 65.76% | 图像预处理(竖线去除) |
| 格子分割 | 71.74% | 方法创新 |
| 无预处理基线 | 75.68% | 格子裁剪优化 |
| **BERT增强** | **82.46%** | 后处理优化 |
| **03.4预处理实验** | **75.68%** | **证明预处理无效** ⚠️ |

**关键insight**: 
- 从53.62% → 75.68%的提升主要来自**方法创新**（格子分割）
- 从75.68% → 82.46%的提升来自**后处理**（BERT）
- 图像预处理在格子分割后**已无优化空间**

### 实验价值

虽然预处理实验没有带来准确率提升,但其价值在于:

1. **证伪假设**: 避免在预处理方向浪费更多时间
2. **聚焦方向**: 明确后续应专注于BERT和模型优化
3. **科学方法**: 系统化对比实验,数据驱动决策
4. **知识积累**: 理解PaddleOCR内部机制,避免重复工作

**研究格言**: "知道什么行不通,和知道什么行得通一样重要。"

### 下一步行动

**立即执行**:
- ✅ 放弃预处理优化
- ⏭️ 开展BERT上下文窗口扩展实验
- ⏭️ 设计繁简体/标点符号修正规则
- ⏭️ 评估模型微调的可行性

**目标**: 从当前82.46%提升至**85%+** (+2.54%)

